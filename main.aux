\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{kang2019few,yan2019meta,wang2019meta}
\citation{gidaris2018dynamic,qi2018low,chen2019closer}
\citation{hariharan2017low,wang2019tafe}
\providecommand \oddpage@label [2]{}
\citation{kang2019few}
\citation{finn2017model,vinyals2016matching,snell2017prototypical}
\citation{ren2015faster}
\citation{he2016deep}
\citation{simonyan2014very}
\citation{ren2015faster}
\newlabel{fig:tfa_arch}{{1}{2}{}{Item.2}{}}
\newlabel{sec:tfa}{{2.1}{2}{}{subsection.2.1}{}}
\newlabel{eq:loss}{{1}{2}{}{equation.2.1}{}}
\citation{gidaris2018dynamic,qi2018low,chen2019closer}
\citation{kang2019few}
\citation{yan2019meta}
\citation{wang2019meta}
\citation{vinyals2016matching}
\citation{ren2015faster}
\citation{he2016deep}
\citation{lin2016feature}
\citation{kang2019few,yan2019meta,wang2019meta}
\citation{kang2019few}
\citation{kang2019few}
\citation{yan2019meta}
\newlabel{sec:meta}{{2.2}{3}{}{subsection.2.2}{}}
\newlabel{sec:exist_benchmark}{{3.1}{3}{}{subsection.3.1}{}}
\citation{kang2019few}
\citation{wang2019meta}
\citation{yan2019meta}
\citation{yan2019meta}
\citation{gupta2019lvis}
\citation{gupta2019lvis}
\citation{gupta2019lvis}
\citation{gupta2019lvis}
\citation{gupta2019lvis}
\citation{gupta2019lvis}
\citation{gupta2019lvis}
\citation{gupta2019lvis}
\citation{gupta2019lvis}
\newlabel{fig:meta_arch}{{2}{4}{Abstraction of the meta-learning based few-shot object detectors. A meta-learner is introduced to acquire task-level meta information and help the model generalize to novel classes through feature re-weighting (\textit {e.g.}, FSRW and Meta R-CNN) or weight generation (\textit {e.g.}, MetaDet). A two-stage training approach (meta-training and meta fine-tuning) with episodic learning is commonly adopted}{figure.2}{}}
\newlabel{tab:main_coco}{{1}{4}{{Few-shot detection performance for the novel categories on the COCO dataset.} Our approach consistently outperforms baseline methods across all shots and metrics.\vspace {2mm}}{table.1}{}}
\newlabel{sec:revised_bench}{{3.2}{4}{}{subsection.3.2}{}}
\newlabel{tab:lvis_bench}{{2}{5}{Generalized object detection benchmarks on LVIS. We compare our approach to the baselines provided in LVIS~\cite {gupta2019lvis}. Our approach outperforms the corresponding baseline across all metrics, backbones, and sampling schemes. \vspace {1mm}}{table.2}{}}
\newlabel{fig:coco_bench}{{3}{5}{Generalized object detection benchmarks on COCO. For each metric, we report the average and 95\% confidence interval computed over 10 random samples}{figure.3}{}}
\newlabel{sec:vis}{{3.3}{5}{}{subsection.3.3}{}}
\newlabel{tab:weight_init}{{3}{5}{Ablation of weight initialization of the novel classifier. \vspace {2mm}}{table.3}{}}
\newlabel{tab:cos_scale}{{4}{5}{Ablation of scaling factor of cosine similarity. \vspace {1mm}}{table.4}{}}
\bibstyle{icml2020}
\bibdata{references}
\bibcite{chen2019closer}{{1}{2019}{{Chen et~al.}}{{Chen, Liu, Kira, Wang, and Huang}}}
\bibcite{dhillon2019baseline}{{2}{2019}{{Dhillon et~al.}}{{Dhillon, Chaudhari, Ravichandran, and Soatto}}}
\bibcite{finn2017model}{{3}{2017}{{Finn et~al.}}{{Finn, Abbeel, and Levine}}}
\bibcite{gidaris2018dynamic}{{4}{2018}{{Gidaris \& Komodakis}}{{Gidaris and Komodakis}}}
\bibcite{gupta2019lvis}{{5}{2019}{{Gupta et~al.}}{{Gupta, Dollar, and Girshick}}}
\bibcite{hariharan2017low}{{6}{2017}{{Hariharan \& Girshick}}{{Hariharan and Girshick}}}
\bibcite{he2016deep}{{7}{2016}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\newlabel{fig:det-vis}{{4}{6}{Success partial and failure cases of our approach on novel classes from COCO. The black boxes are detected objects of irrelevant classes, which can be ignored. \vspace {1mm}}{figure.4}{}}
\bibcite{kang2019few}{{8}{2019}{{Kang et~al.}}{{Kang, Liu, Wang, Yu, Feng, and Darrell}}}
\bibcite{koch2015siamese}{{9}{2015}{{Koch}}{{}}}
\bibcite{landau1988importance}{{10}{1988}{{Landau et~al.}}{{Landau, Smith, and Jones}}}
\bibcite{Lin2014MicrosoftCC}{{11}{2014}{{Lin et~al.}}{{Lin, Maire, Belongie, Hays, Perona, Ramanan, Doll{\'a}r, and Zitnick}}}
\bibcite{lin2016feature}{{12}{2017}{{Lin et~al.}}{{Lin, Dollar, Girshick, He, Hariharan, and Belongie}}}
\bibcite{nichol2018reptile}{{13}{2018}{{Nichol et~al.}}{{Nichol, Achiam, and Schulman}}}
\bibcite{qi2018low}{{14}{2018}{{Qi et~al.}}{{Qi, Brown, and Lowe}}}
\bibcite{ren2015faster}{{15}{2015}{{Ren et~al.}}{{Ren, He, Girshick, and Sun}}}
\bibcite{rusu2018meta}{{16}{2018}{{Rusu et~al.}}{{Rusu, Rao, Sygnowski, Vinyals, Pascanu, Osindero, and Hadsell}}}
\bibcite{samuelson2005they}{{17}{2005}{{Samuelson \& Smith}}{{Samuelson and Smith}}}
\bibcite{simonyan2014very}{{18}{2014}{{Simonyan \& Zisserman}}{{Simonyan and Zisserman}}}
\bibcite{smith2002object}{{19}{2002}{{Smith et~al.}}{{Smith, Jones, Landau, Gershkoff-Stowe, and Samuelson}}}
\bibcite{snell2017prototypical}{{20}{2017}{{Snell et~al.}}{{Snell, Swersky, and Zemel}}}
\bibcite{vinyals2016matching}{{21}{2016}{{Vinyals et~al.}}{{Vinyals, Blundell, Lillicrap, Wierstra, et~al.}}}
\bibcite{wang2019tafe}{{22}{2019{a}}{{Wang et~al.}}{{Wang, Yu, Wang, Darrell, and Gonzalez}}}
\bibcite{wang2019meta}{{23}{2019{b}}{{Wang et~al.}}{{Wang, Ramanan, and Hebert}}}
\bibcite{yan2019meta}{{24}{2019}{{Yan et~al.}}{{Yan, Chen, Xu, Wang, Liang, and Lin}}}
\citation{kang2019few}
\citation{wang2019meta}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few}
\citation{kang2019few,yan2019meta,wang2019meta}
\newlabel{tab:voc_bench}{{5}{9}{Generalized object detection benchmarks on PASCAL VOC. For each metric, we report the average and 95\% confidence interval computed over 30 random samples. \vspace {1mm}}{table.5}{}}
\newlabel{tab:coco_bench}{{6}{10}{Generalized object detection benchmarks on COCO. For each metric, we report the average and 95\% confidence interval computed over 10 random samples. \vspace {1mm}}{table.6}{}}
\newlabel{fig:avg-ap-sup}{{5}{10}{Cumulative means with 95\% confidence intervals across 40 repeated runs, computed on the novel classes of all three splits of PASCAL VOC. The means and variances become stable after around 30 runs}{figure.5}{}}
\newlabel{fig:coco-avg-ap-sup}{{6}{10}{Cumulative means with 95\% confidence intervals across 10 repeated runs, computed on the novel classes of COCO}{figure.6}{}}
